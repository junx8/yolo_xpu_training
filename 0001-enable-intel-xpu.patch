From 2d20c71d3d11d1004563d7725bd939ad005eeb4b Mon Sep 17 00:00:00 2001
From: "Chen,Junx" <junx.chen@intel.com>
Date: Wed, 12 Mar 2025 16:56:01 +0800
Subject: [PATCH] enable intel xpu

Signed-off-by: Chen,Junx <junx.chen@intel.com>
---
 ultralytics/engine/trainer.py    | 4 +++-
 ultralytics/utils/checks.py      | 2 +-
 ultralytics/utils/torch_utils.py | 6 +++++-
 3 files changed, 9 insertions(+), 3 deletions(-)

diff --git a/ultralytics/engine/trainer.py b/ultralytics/engine/trainer.py
index f2a4903a..5b0fcf4b 100644
--- a/ultralytics/engine/trainer.py
+++ b/ultralytics/engine/trainer.py
@@ -174,7 +174,7 @@ class BaseTrainer:
             world_size = len(self.args.device.split(","))
         elif isinstance(self.args.device, (tuple, list)):  # i.e. device=[0, 1, 2, 3] (multi-GPU from CLI is list)
             world_size = len(self.args.device)
-        elif self.args.device in {"cpu", "mps"}:  # i.e. device='cpu' or 'mps'
+        elif self.args.device in {"cpu", "mps", "xpu"}:  # i.e. device='cpu' or 'mps'
             world_size = 0
         elif torch.cuda.is_available():  # i.e. device=None or device='' or device=number
             world_size = 1  # default to device 0
@@ -495,6 +495,8 @@ class BaseTrainer:
                 total = torch.mps.get_mem_info()[0]
         elif self.device.type == "cpu":
             pass
+        elif self.device.type == "xpu":
+            pass
         else:
             memory = torch.cuda.memory_reserved()
             if fraction:
diff --git a/ultralytics/utils/checks.py b/ultralytics/utils/checks.py
index 9a1a217a..0e2e2cd9 100644
--- a/ultralytics/utils/checks.py
+++ b/ultralytics/utils/checks.py
@@ -663,7 +663,7 @@ def check_amp(model):
 
     device = next(model.parameters()).device  # get model device
     prefix = colorstr("AMP: ")
-    if device.type in {"cpu", "mps"}:
+    if device.type in {"cpu", "mps", "xpu"}:
         return False  # AMP only used on CUDA devices
     else:
         # GPUs that have issues with AMP
diff --git a/ultralytics/utils/torch_utils.py b/ultralytics/utils/torch_utils.py
index c70ba7b0..32695e68 100644
--- a/ultralytics/utils/torch_utils.py
+++ b/ultralytics/utils/torch_utils.py
@@ -169,8 +169,9 @@ def select_device(device="", batch=0, newline=False, verbose=True):
     for remove in "cuda:", "none", "(", ")", "[", "]", "'", " ":
         device = device.replace(remove, "")  # to string, 'cuda:0' -> '0' and '(0, 1)' -> '0,1'
     cpu = device == "cpu"
+    xpu = device == "xpu"
     mps = device in {"mps", "mps:0"}  # Apple Metal Performance Shaders (MPS)
-    if cpu or mps:
+    if cpu or mps or xpu:
         os.environ["CUDA_VISIBLE_DEVICES"] = "-1"  # force torch.cuda.is_available() = False
     elif device:  # non-cpu device requested
         if device == "cuda":
@@ -219,6 +220,9 @@ def select_device(device="", batch=0, newline=False, verbose=True):
         # Prefer MPS if available
         s += f"MPS ({get_cpu_info()})\n"
         arg = "mps"
+    elif xpu and torch.xpu.is_available():
+        s += f"MPS ({torch.xpu.get_device_name()})\n"
+        arg = "xpu"
     else:  # revert to CPU
         s += f"CPU ({get_cpu_info()})\n"
         arg = "cpu"
-- 
2.43.0

